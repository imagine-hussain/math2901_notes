\section{Hypothesis Testing}

\subsection{Hypothesis}

\paragraph{Null and Alternative Hypothesis}
\begin{itemize}
  \item \textbf{Null Hypothesis:} Labelled as \(H_0\), this is a claim that, a parameter
    of interest  \(\theta\), takes a values \(\theta_0\). Hence,
      \(H_0\) is of the form  \(\theta = \theta_0\) for some pre-defined
      value of \(\theta_0\).
  \item \textbf{Alternative Hypothesis:} Labelled as \(H_1\),
    this is a more general hypothesis about  \(\theta\) that we accept as true if the
    evidence contradicting the Null Hypothesis is strong enough. \(H_1\) is usually
    of the following forms:
     \begin{itemize}
      \item \(H_1: \theta \neq  \theta_0\),
      \item \(H_1: \theta <  \theta_0\),
      \item \(H_1: \theta >  \theta_0\).
    \end{itemize}
\end{itemize}

\paragraph{Process of Hypothesis Testing}
We take the following steps.
\begin{enumerate}
  \item State the null hypothesis \((H_0)\) and the alternative hypothesis  \((H_1)\).
    By convention, the null-hypothesis is more specific.
  \item Use data to find evidence against null-hypothesis. Common ways is
     \begin{itemize}
       \item Find a statistic to measure how \textit{far} the sata is from what is expected
         if \(H_0\) is true. The approximate distribution, assuming  \(H_0\)
         is true, is called teh \textit{null distribution}.
       \item  Calculate a \(P\)-value. That is, a probability that measures the amount
         of evidence against the null-hypothesis given the observed data.
         The  \(P\)-value is the probability of observing a test statistic
         value more as more or less unususual as the one obseverd, if  \(H_0\)
         is true.
       \item Reach a conclusion about how much evidence there is against \(H_0\).
    \end{itemize}
\end{enumerate}

\subsection{P-Values}

\paragraph{P-values}
The \(P\)-value of an observed statistic is the probability that,
we observe a test statistic that is more \textit{extreme} than the observed
test statistic when  \(H_0\) is true.

\paragraph{Tests for Normal Samples}
For \(X[1, n] \sim \Norm(\mu, \sigma^2)\), we can perform exact hypothesis tests
for \(\mu\) using the main result of the  \(t\)-distribution that \[
  \frac{\overline{X} - \mu}{S/\sqrt{n}} \sim t_{n - 1}
.\] 

Then, testing \(H_0: \mu = \mu_0\) verses any  \(H_1\) of form  \(\mu <, =, > \mu_0\),
the appropriate test-statistic is to calculate  \[
  \frac{\overline{X} - \mu_0}{S/\sqrt{n}}
.\] 


\paragraph{One Sided Hypothesis Test}
A one-sided hypothesis test of a parameter \(\theta\) is of the form \[
  H_0: \theta = \theta_0 \quad \text{ versus } \quad H_1: \theta < \theta_0 \text{ or } \theta > \theta_0
.\] 
\paragraph{Two-sided Hypothesis Test}
A two-sided hypothesis test for \(\theta\) is of the form \[
  H_0: \theta = \theta_0 \quad \text{ versus } \quad H_1: \theta \neq \theta_0
.\] This may often be called a two-tailed test.


\paragraph{Rejection Regoin}
The rejection-region serves as an alternative to \(p\)-value tests and is a set
of values of the test-statistic for which  \(H_0\) is rejected in favour of
 \(H_1\).

To derive a rejection region, we choose a \(p\)-value called the \textit{significance} level
for the test, usually denoted by \(\alpha\).

\paragraph{Type I and II Error}
\begin{itemize}
  \item \textbf{Type I Error:} This occurs when we reject the null-hypothesis, though it is true.
  \item \textbf{Type II Error:} This occurs when we accept the null-hypothesis, though it is false.
\end{itemize}

\paragraph{Type I/II Error and Significance Level}
The \textit{significance} level of a test is the probability of commiting a 
Type I error. That is,
\begin{align*}
  \alpha &= \text{size} \\
         &= \text{significance level} \\
         &= \mathbb{P}(\text{commiting Type I Error}) \\
         &= \mathbb{P}(\text{Reject null-hypothesis that is true})
.\end{align*}


\paragraph{Power of a Statistical Test}
A powerful test is one that has a good chance of rejecting \(H_0\) when it is not  true.
Consider a test with a mean \(\mu\). Then,
\begin{align*}
  \power(\mu) &= \mathbb{P}(\text{Reject null-hypothesis when the true value is } \mu)
              &= \mathbb{P}(\text(reject ) H_0).
.\end{align*}
Observe that \[
  \mathbb{P}(\text{Type II Error}) = 1 - \power(\mu)
.\] 

\paragraph{Testing With Estimators}
Suppose that the null-hypothesis is of the form that a parameter is equal to some value.
Then, we can get an estimator of that parameter and use the approximate distribution of that
parameter to test the null-hypothesis.

