\section{Methods for Parameter Estimation and Inference}

\paragraph{Estimates vs Estimators}
It is important to differentiate the following. An estimate of a parameter \(\theta\)
is a function \(\hat{\theta} = \hat{\theta}(x_1, x_2, \ldots, x_n)\).

An estimator is the same function \(\hat{\theta} = \hat{\theta}(x_1, \ldots, x_n)\) ove
observable random variables. That is, the estimator is itself a random variable with examinable
properties while the estimate is an actual number. That is, the realised value of an estimator

\paragraph{Notation}
Denote \(f_x\) as  \(f\) because writing that subscript is alot of effort.



\subsection{Method of Moments}
\paragraph{Method of Moments Estimation}
Let \(x_1, \ldots, x_n\) be observations from the model \(f\) where,  \[
  f(x; \theta_1, \ldots, \theta_k)
.\] 

As there are \(k\) parameters a systemof  \(k\) equations forms, that equates the moments of  \(f_x\)
with their sample counterparts.
\begin{align*}
  \mathbb{E}(X^1) &= \frac{1}{n} \sum_i x_i \\
  \mathbb{E}(X^2) &= \frac{1}{n} \sum_i x^2_i \\
  \vdots \\
  \mathbb{E}(X^k) &= \frac{1}{n} \sum_i x^k_i
.\end{align*}
The \textit{method of moments} estimates are the solutions of these equations in
terms of \(\theta_1, \ldots, \theta_k\).

\paragraph{Consistency of Method of Moments Estimators}
By the weak law of large numbers, we can deduce that
\(\hat{\theta}_j \xrightarrow{\mathbb{P}} \theta_j\).
That is, the method of moments leads to consistent estimations.
However, this is not optimal as we can do better in terms of standard error and,
mean squared error.

\subsection{Maximum Likelihood Estimator}

\paragraph{Likelihood Function}
Let \(x[1, n]\) be observations from a random variable with the pdf \(f\)
where  \[
  f(x) = f(x; \theta), \theta \in \Theta
.\] The \textit{likelihood function} \(\mathcal{L}\) of \(\theta\) is \[
  \mathcal{L}(\theta) = f(x_1; \theta) \cdots f(x_n; \theta)
  = \prod_{i = 1}^n f(x_i; \theta), \quad \theta \in \Theta
.\] 
Similarly, we have the log-likelihood function of \(\theta\), \[
  \ell(\theta) = \ln{\mathcal{L}(\theta)} = \sum_i \ln{f(x_i; \theta)}
.\] 

\paragraph{Maximum Likelihood Estimate}
Suppose there is \(x[1, n]\) observations from the function \(f\) where \[
  f(x) = f(x; \theta), \quad \text{ for } \theta \in  \Theta
.\]
The maximum likelihood estimate of \(\theta\) is the choice \[
  \hat{\theta} = \theta, \text{ maximising } \mathcal{L}(\theta) \text{ over } \theta \in \Theta
.\] 

\paragraph{Equivalence of Log Likelihood Maximisation}
The place where \(\mathcal{\theta}\) achieves its maximum over \(\theta \in Theta\)
is also where \[
  \ell(\theta) = \ln \{\mathcal{L}(\theta)\} = \sum_{i} \ln \{f(x_i; \theta)\} 
\]  attains its maximum. Therefore, the maximum likelihood estimate of \(\theta\)
is equivalently, \[
  \hat{\theta} = \theta \text{ that maximises } \ell(\theta) \text{ over } \Theta
.\] 

\paragraph{Non-Smooth Functions and Indicators}
Not all functions that are of the form \(f(x; \theta)\) are smooth. As such, we
may use the indicator function for a logical condition \(\mathcal{P}\) given by
\[
  \mathbb{I}(\mathcal{P}) = \begin{cases}
    1 &= \text{ if } \mathcal{P} \text{ is true} \\
    0 &= \text{ if } \mathcal{P} \text{ is false}
  \end{cases}
.\]
Then, we may try to maximise \(\mathcal{L}(\theta)\cdot \mathbb{I}(\mathcal{P})\).

\paragraph{Indicators and Intersection}
For any logical conditions \(\mathcal{P}, \mathcal{Q}\), \[
  \mathbb{I}(\mathcal{P} \cap \mathcal{Q}) = \mathbb{I}(\mathcal{P})\mathbb{I}(\mathcal{Q})
.\] 

\paragraph{Consistency of Maximul Likelihood Estimators}
The maximum likelihood estimator \(\hat{\theta}_n\) of \(\theta\)
is consisted, that is \(\hat{\theta}_n \xrightarrow{\mathbb{P}} \theta\),
if the following conditions hold.
\begin{itemize}
  \item The domain of \(x\) does not depend on  \(\theta\). That is,  all \(f(x; \theta)\)
    are non-zero over the same set, irrespective of \(\theta\).
  \item If \(\theta \neq \vartheta\) then \( f(x; \theta) \neq f(x; \vartheta)\).
    Equivalently, if  \(\theta = \vartheta\) then \(f(x; \theta) = f(x; \vartheta)\).
  \item The MLE \(\hat{\theta}\) is unique and lies in the interior of \(\Theta\).
\end{itemize}

\paragraph{Equivariance under Function Transformation}
If \(\hat{\theta}\) is a MLE of \(\theta\) then for all \(g\),  \[
  g(\hat{\theta}) \text{ is the MLE of } g(\theta)
.\] 


\subsection{Variance and Standard Error}
\paragraph{Assumptions}
\begin{itemize}
  \item Let \(X[1, n] \sim f(x; \theta)\) be independent continuous random variable for some  \(\theta \in  \Theta\).
  \item Let the corresponding log-likelihood (non-normalised) function be \[
      \ell_n(\theta) = \sum_{i = 1}^n \ln f(XX_i; \theta)
    .\]
  \item Assume \(f(\cdot ; \theta)\) is twice differen=tiable with respect to \(\theta\).
  \item Assume \(\int f(x; \theta) dx\) is integrable under the integral.
\end{itemize}

\paragraph{Fisher Score and Information}
We define the fisher score as \[
  S_n(\theta) = \ell_n'(\theta)
.\]
Further, the Fisher information is defined as \[
  I_n(\theta) = - \mathbb{E}_\theta \ell_n'' (\theta),
.\] where the expecation is taked with respect to \(\theta\).

\paragraph{Properties of the Fisher Score and Information} \[
  \mathbb{E}_\theta \left( S_n(\theta) \right)  = 0.
.\] Also, \[
I_n(\theta) = \mathbb{E}_\theta \left[ \ell_n'(\theta) \right]^2 = \Var_\theta(S_n(\theta))
.\] 

\paragraph{MSE of Max Likelihood Estimator} Let \(\hat{\theta}_n\) be a maximum likelihood edtimator of
\(\theta\). Then, as \(n \to \infty\), \[
  I_n(\theta) \cdot \Var(\hat{\theta}_n) \xrightarrow{\mathbb{P}} 1
.\] 
Hence, we have the standard error \[
  \Se(\hat{\theta}) \approx \frac{1}{\sqrt{I_n (\hat{\theta})} }
.\] 

\paragraph{Asymptomatic Normality of the Maximum Likelihood Estimators}
This may be one of the \textit{most important} theorems in statistics. Suppose that
we follow the smoothness assumptions from earlier. Then, \[
  \frac{\hat{\theta} - \theta}{\sqrt{\Var(\hat{\theta})}} \xrightarrow{d} \Norm(0, 1)
  \quad \text{ and } \quad
  \frac{\hat{\theta} - \theta}{\Se(\hat{\theta})} \xrightarrow{d} \Norm(0, 1),
\] where \[
  \Se(\hat{\theta}) = \frac{1}{\sqrt{I_n(\theta)}}
.\] 
Hence, not only does the MLE make for a useful estimator but, we can also
make inferences about parameters as the distribution and standard error allow us to construct
confidence intervals for \(\theta\) using \(\hat{\theta}\)'s data, for any family
of distributions with known form.

\paragraph{Non-Standard Normality}
Since, \[
  \frac{\hat{\theta} - \theta}{\sqrt{\Var(\hat{\theta})}} \xrightarrow{d} \Norm(0, 1)
,\] we may approximately model \[
  \hat{\theta} \sim \Norm(\theta, \Var(\hat{\theta}))
.\] 

\paragraph{TODO: Delta Method for extending normality}



